{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 00:33:25.650946: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-31 00:33:27.516996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64\n",
      "2023-12-31 00:33:27.517084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64\n",
      "2023-12-31 00:33:27.517091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 256, 3)       6         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 16, 16, 2048)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 256)       4718848   \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       295040    \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 3)         1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,677,129\n",
      "Trainable params: 28,624,009\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ResNet-18 without the top layer (classifier)\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Modify the input layer to accept grayscale images\n",
    "input_layer = layers.Input(shape=(256, 256, 1))\n",
    "x = layers.Conv2D(3, (1, 1))(input_layer)  # Convert grayscale to pseudo-RGB\n",
    "x = base_model(x)\n",
    "\n",
    "# Add decoder layers for colorization\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load a pre-trained ResNet-18 without the top layer (classifier)\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Modify the input layer to accept grayscale images\n",
    "input_layer = layers.Input(shape=(256, 256, 1))\n",
    "x = layers.Conv2D(3, (1, 1))(input_layer)  # Convert grayscale to pseudo-RGB\n",
    "x = base_model(x)\n",
    "\n",
    "# Add decoder layers for colorization\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
